{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating Sentences From Italian to English with FNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Transformer FNet model trained on over 300 000 examples to translate sentences from Italian to English. Model was trained using Google Colab free GPU for 13 epochs on train dataset (size: 246 632) and then fine-tuned with learning rate reduced tenfold on validation dataset (size: 52850). Model losses before and after fine-tuning are presented in the table below. Digits indicate number of epochs during fine-tuning.\n",
    "\n",
    "\n",
    "|  | train | train+val 2 | train+val 3 | train+val 4 | train+val 6 |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| **Loss** | 0.2363 | 0.2032 | 0.2012 | **0.2009** | 0.2019 |\n",
    "\n",
    "\n",
    "> Since self-attention layer is replaced with Fourier Transform in Encoder part of the model total training time is reduced by ~80%. Despite haveing less parameters Fnet is able to achieve ~90% of *regular* Transofrmer's accuracy. Training time in total took around 1.5h. Model is also a bit overfitting, solution may be to reduce model size, further implement regularization or get some more data.\n",
    "\n",
    "> Later model was evaluated with BLEU metric, but since translating entire test set (size: 52850) takes long time, only random 10 000 sentences were chosen and evaluated. BLEU score for selected sentences was 0.77 which is surprisingly high :V <br> \n",
    "The answer may be that there are many short sentences which are easy to predict with such model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import tensorflow.data\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "from nltk.translate import bleu_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# disable warnings for nltk BLEU\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsConfig:\n",
    "    \n",
    "    embedding_dim = 128 # 256\n",
    "    vocab_size = 10000\n",
    "    maxlen = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(layers.Layer):\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super(Embeddings, self).__init__(**kwargs)\n",
    "        \n",
    "        self.embedding_dim = config.embedding_dim\n",
    "        self.maxlen = config.maxlen\n",
    "        self.vocab_size = config.vocab_size\n",
    "        \n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=config.maxlen,\n",
    "            output_dim=config.embedding_dim\n",
    "        )\n",
    "        \n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=config.vocab_size,\n",
    "            output_dim=config.embedding_dim\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        positions = K.arange(start=0, stop=self.maxlen, step=1)\n",
    "        positions = self.position_embeddings(positions)\n",
    "        x = self.token_embeddings(x)\n",
    "        return x + positions\n",
    "    \n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerConfig:\n",
    "    \n",
    "    embedding_dim = 128 #256\n",
    "    dense_dim = 256 #512\n",
    "    num_heads = 8 # 6\n",
    "    dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNetEncoder(layers.Layer):\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super(FNetEncoder, self).__init__(**kwargs)\n",
    "        \n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=config.dense_dim, activation='relu'),\n",
    "                layers.Dense(units=config.embedding_dim)\n",
    "            ]\n",
    "        )\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        fourier = tf.signal.fft2d(tf.cast(x, tf.complex64))\n",
    "        real = tf.math.real(fourier)\n",
    "    \n",
    "        residual = self.norm1(real + x)\n",
    "        ffnn = self.dense_proj(residual)\n",
    "        return self.norm2(residual + ffnn)\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'FNetEncoder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        \n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(config.dropout)\n",
    "        self.dropout2 = layers.Dropout(config.dropout)\n",
    "        self.supports_masking = True\n",
    "        \n",
    "        self.attention1 = layers.MultiHeadAttention(\n",
    "            num_heads=config.num_heads,\n",
    "            key_dim=config.embedding_dim,\n",
    "            name='att_1'\n",
    "        )\n",
    "        \n",
    "        self.attention2 = layers.MultiHeadAttention(\n",
    "            num_heads=config.num_heads,\n",
    "            key_dim=config.embedding_dim,\n",
    "            name='att_2'\n",
    "        )\n",
    "        \n",
    "        self.dense_proj = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(units=config.dense_dim, activation='relu'),\n",
    "            layers.Dense(units=config.embedding_dim)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def call(self, x, enc_out, mask=None):\n",
    "        casual_mask = self.get_casual_mask(x)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, casual_mask)\n",
    "        \n",
    "        attention1 = self.attention1(\n",
    "            query=x, \n",
    "            key=x, \n",
    "            value=x, \n",
    "            attention_mask=casual_mask\n",
    "        )\n",
    "        \n",
    "        residual1 = self.dropout1(attention1)\n",
    "        residual1 = self.norm1(x + attention1)\n",
    "        attention2 = self.attention2(\n",
    "            query=residual1,\n",
    "            key=enc_out,\n",
    "            value=enc_out,\n",
    "            attention_mask=padding_mask\n",
    "        )\n",
    "        \n",
    "        residual2 = self.norm2(residual1 + attention2)\n",
    "        ffnn = self.dense_proj(residual2)\n",
    "        ffnn = self.dropout2(ffnn)\n",
    "        return self.norm3(residual2 + ffnn)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_casual_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Decoder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_conf = TransformerConfig()\n",
    "embeddings_conf = EmbeddingsConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def connect_model():\n",
    "    enc_inputs = layers.Input(shape=(None, ), name='encoder_inputs')\n",
    "    x = Embeddings(embeddings_conf)(enc_inputs)\n",
    "    enc_out = FNetEncoder(transformer_conf)(x)\n",
    "\n",
    "    dec_inputs = layers.Input(shape=(None, ), name='decoder_inputs')\n",
    "    dec_state_inputs = layers.Input(shape=(None, embeddings_conf.embedding_dim), name='decoder_state_inputs')\n",
    "\n",
    "    x = Embeddings(embeddings_conf)(dec_inputs)\n",
    "    x = Decoder(transformer_conf)(x, dec_state_inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    dec_outputs = layers.Dense(embeddings_conf.vocab_size, activation='softmax', name='decoder_outputs')(x)\n",
    "\n",
    "    decoder = keras.Model([dec_inputs, dec_state_inputs], dec_outputs)\n",
    "    decoder_outputs = decoder([dec_inputs, enc_out])\n",
    "    model = keras.Model([enc_inputs, dec_inputs], decoder_outputs, name='fnet')\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = connect_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embeddings (Embeddings)         (None, 20, 128)      1282560     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "f_net_encoder (FNetEncoder)     (None, 20, 128)      66432       embeddings[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 20, 10000)    3694224     decoder_inputs[0][0]             \n",
      "                                                                 f_net_encoder[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,043,216\n",
      "Trainable params: 5,043,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    name = path.split('/')[-1]\n",
    "    with open(f'{path}/{name}.pkl', 'rb') as file:\n",
    "        spec = pkl.load(file)\n",
    "        \n",
    "    dataset = tensorflow.data.experimental.load(path, element_spec=spec)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/italian/'\n",
    "train_ds = load_dataset(path+'train_ds')\n",
    "val_ds = load_dataset(path+'val_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience=3, verbose=1, monitor='val_loss')\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath='checkpoints/model.{epoch:02d}-{val_loss:.2f}.h5', save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training done in Google Colab\n",
    "# after 13 epochs early stopping \n",
    "# model trained for around 1.5h\n",
    "his = model.fit(train_ds,\n",
    "                validation_data=val_ds,\n",
    "                epochs=30,\n",
    "                shuffle=True,\n",
    "                callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Models/ok/training.pkl', 'rb') as file:\n",
    "    training_result = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mark_last_element(ax, arr):\n",
    "    x = len(arr)-1\n",
    "    y = arr[-1]\n",
    "    ax.text(x, y, round(arr[-1], 2), ha='right')\n",
    "\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "plt.plot(training_result['loss'], label='loss')\n",
    "plt.plot(training_result['val_loss'], label='val_loss')\n",
    "\n",
    "mark_last_element(fig.get_axes()[0], training_result['loss'])\n",
    "mark_last_element(fig.get_axes()[0], training_result['val_loss'])\n",
    "\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectorizer(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        config = pkl.load(file)\n",
    "    vec = layers.experimental.preprocessing.TextVectorization.from_config(config['config'])\n",
    "    # bugged so I have to adapt on dummy data\n",
    "    vec.adapt(['dummy'])\n",
    "    vec.set_weights(config['weights'])\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_back_from_tokens(vectorizer, tokens):\n",
    "    # not efficient af and probably also not safe\n",
    "    token_dict = {k:v for k, v in list(enumerate(vectorizer.get_vocabulary()))}\n",
    "    result = ''\n",
    "    if not isinstance(tokens, np.ndarray):\n",
    "        tokens = tokens.numpy()\n",
    "    for i in tokens:\n",
    "        # start and end tokens\n",
    "        if i == 2 or i == 3:\n",
    "            continue\n",
    "        # pad token\n",
    "        elif i == 0:\n",
    "            break\n",
    "        result += token_dict[i] + ' '\n",
    "        \n",
    "    # remove redundant space\n",
    "    return result[:-1]\n",
    "\n",
    "\n",
    "# check if it works\n",
    "# print('INPUT:\\t', convert_back_from_tokens(eng_vec, ytest[0]))\n",
    "# print('TARGET:\\t', convert_back_from_tokens(ita_vec, xtest[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vectorizers\n",
    "eng_vec = load_vectorizer('../Vectorizers/vec_eng.pkl')\n",
    "ita_vec = load_vectorizer('../Vectorizers/vec_ita.pkl')\n",
    "\n",
    "# load weights\n",
    "model.load_weights('../Models/fine-tuned/weights-fine-tuned-4.h5')\n",
    "\n",
    "# load test_ds and test_pkl\n",
    "test_ds = load_dataset('../Data/italian/test_ds')\n",
    "\n",
    "with open('../Data/italian/test.pkl', 'rb') as file:\n",
    "    test = pkl.load(file)\n",
    "    xtest = test[0]['encoder_inputs']\n",
    "    ytest = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on test_ds:  0.201\n"
     ]
    }
   ],
   "source": [
    "# trained on train_ds and  fine tuned on val_ds (4 epochs)\n",
    "loss = model.evaluate(test_ds, verbose=2)\n",
    "print('loss on test_ds: ', round(loss, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the doors have been open'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_sentence(sentence):\n",
    "    encoder_input = ita_vec([sentence])\n",
    "    decoder_input = eng_vec(['ssss'])[:, :-1].numpy()\n",
    "    \n",
    "    for i in range(embeddings_conf.maxlen):\n",
    "        probs = model.predict({'encoder_inputs': encoder_input, \n",
    "                              'decoder_inputs': decoder_input})\n",
    "        token = np.argmax(probs[:, i, :])\n",
    "        if token == 3: # eeee\n",
    "            break\n",
    "        try:\n",
    "            decoder_input[:, i+1] = token\n",
    "        except IndexError: \n",
    "            break\n",
    "    return convert_back_from_tokens(eng_vec, decoder_input[0])\n",
    "\n",
    "\n",
    "# check check\n",
    "translate_sentence('Le porte sono state aperte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:\t Le porte sono state aperte\n",
      "TRANSLATED:\t the doors have been open\n",
      "ACTUAL:\t\t The doors have been opened\n",
      "BLEU{1-4}:\t 0.6 0.55 0.46 0.0\n"
     ]
    }
   ],
   "source": [
    "def compare_sentences(sentence, actual_translation, calculate_bleu=True):\n",
    "    translated_sentence = translate_sentence(sentence)\n",
    "    print('ORIGINAL:\\t', sentence)\n",
    "    print('TRANSLATED:\\t', translated_sentence)\n",
    "    print('ACTUAL:\\t\\t', actual_translation)\n",
    "    if calculate_bleu == True:\n",
    "        # BLEU 1-4 metric\n",
    "        weights = [[1.0/i for x in range(i)] for i in range(1, 5)]\n",
    "        scores = [\n",
    "            bleu_score.sentence_bleu([actual_translation.split()], translated_sentence.split(), weights=w)\n",
    "            for w in weights\n",
    "        ]\n",
    "        scores = list(map(lambda x: round(x, 2), scores))\n",
    "        print('BLEU{1-4}:\\t', *scores)\n",
    "\n",
    "        \n",
    "# check if it works\n",
    "compare_sentences('Le porte sono state aperte', 'The doors have been opened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of tokens to list of strings \n",
    "def convert_all(x, y):\n",
    "    X = [convert_back_from_tokens(ita_vec, tokens) for tokens in x]\n",
    "    Y = [convert_back_from_tokens(eng_vec, tokens) for tokens in y]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:\t lha detto\n",
      "TRANSLATED:\t did you say that\n",
      "ACTUAL:\t\t did she say it\n",
      "BLEU{1-4}:\t 0.5 0.0 0.0 0.0\n",
      "\n",
      "ORIGINAL:\t io sono [UNK]\n",
      "TRANSLATED:\t im a trainee\n",
      "ACTUAL:\t\t im busy as a bee\n",
      "BLEU{1-4}:\t 0.34 0.0 0.0 0.0\n",
      "\n",
      "ORIGINAL:\t solitamente sono a casa il lunedì pomeriggio\n",
      "TRANSLATED:\t i usually go home on mondays\n",
      "ACTUAL:\t\t im usually at home monday afternoons\n",
      "BLEU{1-4}:\t 0.33 0.0 0.0 0.0\n",
      "\n",
      "ORIGINAL:\t ho incontrato in biblioteca lunedì\n",
      "TRANSLATED:\t i met in the library on monday\n",
      "ACTUAL:\t\t i met tom in the library on monday\n",
      "BLEU{1-4}:\t 0.87 0.79 0.69 0.61\n",
      "\n",
      "ORIGINAL:\t sta ancora dormendo\n",
      "TRANSLATED:\t are you still sleeping\n",
      "ACTUAL:\t\t tom is still asleep\n",
      "BLEU{1-4}:\t 0.25 0.0 0.0 0.0\n",
      "\n",
      "ORIGINAL:\t possiamo aver fatto un errore\n",
      "TRANSLATED:\t we can make a mistake\n",
      "ACTUAL:\t\t we may have made a mistake\n",
      "BLEU{1-4}:\t 0.49 0.32 0.0 0.0\n",
      "\n",
      "ORIGINAL:\t [UNK] la finestra\n",
      "TRANSLATED:\t they [UNK] the window\n",
      "ACTUAL:\t\t lets open the window\n",
      "BLEU{1-4}:\t 0.5 0.41 0.0 0.0\n",
      "\n",
      "ORIGINAL:\t dovrebbe [UNK]\n",
      "TRANSLATED:\t you should be ashamed\n",
      "ACTUAL:\t\t you should know it\n",
      "BLEU{1-4}:\t 0.5 0.41 0.0 0.0\n",
      "\n",
      "ORIGINAL:\t quelle scarpe sono troppo piccole per lei\n",
      "TRANSLATED:\t those shoes are too small for you\n",
      "ACTUAL:\t\t those shoes are too small for you\n",
      "BLEU{1-4}:\t 1.0 1.0 1.0 1.0\n",
      "\n",
      "ORIGINAL:\t ha del nastro [UNK]\n",
      "TRANSLATED:\t do you have any tape\n",
      "ACTUAL:\t\t do you have any tape\n",
      "BLEU{1-4}:\t 1.0 1.0 1.0 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert back 100 samples from test \n",
    "# and pick random 10 just to see the overall result\n",
    "input_sentences, target_sentences = convert_all(xtest[:100], ytest[:100])\n",
    "\n",
    "amount = 10\n",
    "indexes = np.random.randint(0, len(input_sentences), size=amount)\n",
    "for i in indexes:\n",
    "    compare_sentences(input_sentences[i], target_sentences[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a long, long time to execute \n",
    "# so i'll store it in a .txt file\n",
    "# all_inputs, all_targets = convert_all(xtest, ytest)\n",
    "\n",
    "# with open('../Temp/sentence_pairs.txt', 'w', encoding='utf-8') as file:\n",
    "#     for x, y in zip(all_inputs, all_targets):\n",
    "#         file.write(f'{x}\\t{y}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Temp/sentence_pairs.txt', 'r', encoding='utf-8') as file:\n",
    "    all_inputs, all_targets = [], []\n",
    "    for line in file.readlines():\n",
    "        inp, trg = line.strip('\\n').split('\\t')\n",
    "        all_inputs.append(inp)\n",
    "        all_targets.append([trg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff651311b6644038553dd60f55eeaf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# since translating entire test set is expensive \n",
    "# I will pick 10 000 random sentences, translate and calculate BLUE \n",
    "amount = 10000\n",
    "indexes = np.random.randint(0, len(all_inputs), size=amount)\n",
    "\n",
    "translated_sentences = [translate_sentence(all_inputs[i]) for i in tqdm(indexes)]\n",
    "actual_sentences = [all_targets[i] for i in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for 10000 samples is: 0.77\n"
     ]
    }
   ],
   "source": [
    "bleu = bleu_score.corpus_bleu(actual_sentences, translated_sentences)\n",
    "print(f'BLEU score for {amount} samples is: {round(bleu, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
